import streamlit as st
import google.generativeai as genai
import random
import time

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(page_title="Bae ‚ù§Ô∏è", page_icon="‚ù§Ô∏è", layout="centered")

# --- BACKEND : CONFIGURATION IA & S√âCURIT√â ---
if "GEMINI_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        model = genai.GenerativeModel('gemini-1.5-flash')
        ia_active = True
    except:
        ia_active = False
else:
    ia_active = False

# --- LOGIQUE DE R√âPONSE (HYBRIDE IA + MANUEL) ---
def get_intelligent_response(user_input):
    # 1. Si l'IA est active, on l'utilise avec un prompt ultra-pr√©cis
    if ia_active:
        try:
            prompt = f"""
            Tu es le petit ami d'Ivette (Babe ‚ù§Ô∏è). Tu es calme, protecteur, un peu dr√¥le et tr√®s aimant.
            Analyse son message : {user_input}
            
            R√àGLES :
            - R√©ponds comme si tu √©tais dans une inbox Telegram (court, 2-4 phrases).
            - Si elle est triste : sois un pilier, tr√®s doux.
            - Si elle est en col√®re : sois solidaire, ne la contredis pas.
            - Si elle est joyeuse : sois son premier fan, tr√®s enthousiaste.
            - Utilise 1 seul emoji (‚ù§Ô∏è, ü´Ç, ‚ú®, üò§).
            - Ne parle JAMAIS du pass√© sauf si elle insiste.
            """
            response = model.generate_content(prompt)
            return response.text
        except:
            pass # Si l'IA √©choue, on passe au manuel ci-dessous

    # 2. Syst√®me de secours (Si l'IA bug)
    text = user_input.lower()
    if any(w in text for w in ["triste", "mal", "pleurer", "fatigue", "seul"]):
        return "Je sens que c'est lourd ce soir... pose tout, je suis l√†. Respire avec moi Babe ‚ù§Ô∏è"
    elif any(w in text for w in ["c√¢lin", "calin", "bras", "hug"]):
        return "Viens l√†... je ferme les yeux et je te serre tr√®s fort. Tu sens ? ü´Ç"
    else:
        return "Je t'√©coute mon c≈ìur, dis-moi tout ce que tu as sur le cerveau ‚ù§Ô∏è"

# --- FRONTEND : DESIGN VIOLET & SPARKS ---
st.markdown("""
    <style>
    .stApp { background: radial-gradient(circle at center, #1a0b2e 0%, #0d1117 100%); color: white; }
    
    .chat-header {
        position: fixed; top: 0; left: 0; width: 100%; background: rgba(45, 20, 70, 0.9);
        backdrop-filter: blur(15px); padding: 15px; text-align: center; z-index: 1000;
        border-bottom: 1px solid rgba(155, 89, 182, 0.3);
    }
    .chat-header h2 { color: #e0b0ff !important; margin: 0; font-size: 20px; }
    
    /* Bulles Telegram Custom */
    [data-testid="stChatMessage"] { background-color: transparent !important; }
    
    .st-emotion-cache-1ghh3y3 { 
        background-color: #4a148c !important; color: white !important;
        border-radius: 18px 18px 18px 4px !important; border: 1px solid #7b1fa2 !important;
    }
    .st-emotion-cache-janbn0 { 
        background-color: #2c3e50 !important; color: white !important;
        border-radius: 18px 18px 4px 18px !important;
    }
    [data-testid="stChatMessageAvatarUser"], [data-testid="stChatMessageAvatarAssistant"] { display: none; }

    /* Input fixe en bas */
    [data-testid="stChatInput"] {
        border-radius: 30px !important; background-color: #161b22 !important;
        border: 1px solid #4a148c !important;
    }
    </style>
    <div class="chat-header"><h2>Bae ‚ù§Ô∏è</h2><div style="color:#2ecc71; font-size:11px;">‚óè en ligne</div></div>
    """, unsafe_allow_html=True)

# --- GESTION DE LA CONVERSATION ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Coucou Babe ‚ù§Ô∏è Je suis l√†. Comment s'est pass√©e ta journ√©e ?"}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

if prompt := st.chat_input("√âcris √† ton Bae..."):
    with st.chat_message("user"):
        st.write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.spinner(""):
            full_response = get_intelligent_response(prompt)
            time.sleep(1) # Simulation de frappe
            st.write(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})